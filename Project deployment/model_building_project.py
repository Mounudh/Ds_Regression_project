# -*- coding: utf-8 -*-
"""Model_building_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11kfauH74binbZnBKxPWMy5PfdKOSMGku
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/Regrerssion_energy_production_data (2).csv')
df.head()

import numpy as np
Q1 = np.percentile(df["temperature"],25)
Q1
Q2 = np.percentile(df["temperature"],50)
Q3 = np.percentile(df["temperature"],75)
IQR = Q3-Q1
IQR
LW = Q1 - (1.5*IQR)
UW = Q3 + (1.5*IQR)

df[df["temperature"]<LW]
df[df["temperature"]>UW]

len(df[(df["temperature"]<LW) | (df["temperature"]>UW)])

# df["temperature"]=np.where(
#     df["temperature"]>UW,
#     UW,
#     np.where(
#     df["temperature"]<LW,
#     LW,
#    df["temperature"]
#    )
#     )


# In[15]:


import numpy as np
Q1 = np.percentile(df["exhaust_vacuum"],25)
Q1
Q2 = np.percentile(df["exhaust_vacuum"],50)
Q3 = np.percentile(df["exhaust_vacuum"],75)
IQR = Q3-Q1
IQR
LW = Q1 - (1.5*IQR)
UW = Q3 + (1.5*IQR)

df[df["exhaust_vacuum"]<LW]
df[df["exhaust_vacuum"]>UW]

len(df[(df["exhaust_vacuum"]<LW) | (df["exhaust_vacuum"]>UW)])

# df["exhaust_vacuum"]=np.where(
#     df["exhaust_vacuum"]>UW,
#     UW,
#     np.where(
#     df["exhaust_vacuum"]<LW,
#     LW,
#    df["exhaust_vacuum"]
#    )
#     )


# # checking null values on amb_pressure column

# In[16]:


df['amb_pressure'].max()


# In[17]:


df['amb_pressure'].min()


# In[18]:


# percentile25 = 25/100 * 9569
# percentile25   # index value of 2392 = 1015


# In[19]:


percentile25or = 1009.100000


# In[20]:


# percentile75 = 75/100 * 9569
# percentile75   # index value of 7176 = 1011


# In[21]:


percentile75or = 1017.260000


# In[22]:


iqr1 =  percentile75or - percentile25or


# In[23]:


iqr1


# In[24]:


lqr = (percentile25or) - (1.5 * -4)
lqr


# In[25]:


upr = (percentile75or) + (1.5 * iqr1)
upr


# In[ ]:





# In[26]:


import numpy as np
Q1 = np.percentile(df["amb_pressure"],25)
Q1
Q2 = np.percentile(df["amb_pressure"],50)
Q3 = np.percentile(df["amb_pressure"],75)
IQR = Q3-Q1
IQR
LW = Q1 - (1.5*IQR)
UW = Q3 + (1.5*IQR)

df[df["amb_pressure"]<LW]
df[df["amb_pressure"]>UW]

len(df[(df["amb_pressure"]<LW) | (df["amb_pressure"]>UW)])

(df[(df["amb_pressure"]<LW) | (df["amb_pressure"]>UW)])

# df["amb_pressure"]=np.where(
#     df["amb_pressure"]>UW,
#     UW,
#     np.where(
#     df["amb_pressure"]<LW,
#     LW,
#    df["amb_pressure"]
#    )
#     )


# # checking null values on  r_humidity column

# In[27]:


df['r_humidity'].max()


# In[28]:


df['r_humidity'].min()


# In[29]:


percent25 = 63.327500


# In[30]:


percent75 = 84.830000


# In[31]:


iqr2 =  percent75 - percent25
iqr2


# In[32]:


lqr = (percent25) - (1.5 * iqr2)
lqr


# In[33]:


upr = (percent75) + (1.5 * iqr2)
upr


# In[34]:


import numpy as np
Q1 = np.percentile(df["r_humidity"],25)
Q1
Q2 = np.percentile(df["r_humidity"],50)
Q3 = np.percentile(df["r_humidity"],75)
IQR = Q3-Q1
IQR
LW = Q1 - (1.5*IQR)
UW = Q3 + (1.5*IQR)

df[df["r_humidity"]<LW]
df[df["r_humidity"]>UW]

len(df[(df["r_humidity"]<LW) | (df["r_humidity"]>UW)])

(df[(df["r_humidity"]<LW) | (df["r_humidity"]>UW)])

# df["r_humidity"]=np.where(
#     df["r_humidity"]>UW,
#     UW,
#     np.where(
#     df["r_humidity"]<LW,
#     LW,
#    df["r_humidity"]
#    )
#     )


# In[35]:


df.shape


# In[36]:


import matplotlib.pyplot as plt
from scipy.stats import skew
import seaborn as sns
for col in df:
    print(col)
    print(skew(df[col]))
    plt.figure()
    sns.boxplot(df[col])
    plt.show()

list(df)

import matplotlib.pyplot as plt
def plot_boxplot(df,ft):
    df.boxplot(column=[ft])
    plt.grid(False)
    plt.show()

plot_boxplot(df, "temperature")
plot_boxplot(df, "exhaust_vacuum")
plot_boxplot(df, "amb_pressure")
plot_boxplot(df, "r_humidity")
plot_boxplot(df, "energy_production")




def outliers(df,ft):
    Q1 = df[ft].quantile(0.25)
    Q3 = df[ft].quantile(0.75)
    IQR = Q3-Q1

    lower_bound = Q1-1.5*IQR
    upper_bound = Q3 + 1.5*IQR
    ls = df.index[(df[ft]<lower_bound) | (df[ft] > upper_bound)]
    return ls



index_list = []
for feature in ["temperature","exhaust_vacuum","amb_pressure","r_humidity","energy_production"]:
    index_list.extend(outliers(df,feature))


index_list

def remove(df,ls):
    ls = sorted(set(ls))
    df = df.drop(ls)
    return df

df_cleaned = remove(df,index_list)
df_cleaned.shape



# In[37]:


df_cleaned.shape



# In[38]:


df_cleaned.boxplot(column="r_humidity",vert = False)



# In[39]:


df_cleaned.boxplot(column="amb_pressure",vert = True)


# In[40]:


df_cleaned.head(1)


# In[41]:


import matplotlib.pyplot as plt
plt.figure(figsize=(30,10))
plt.scatter(df_cleaned["temperature"],df_cleaned["energy_production"],color = "red")
plt.show()
plt.title("tem")
plt.figure(figsize=(30,7))


# In[42]:


import matplotlib.pyplot as plt

plt.figure(figsize=(30,10))
plt.scatter(df_cleaned["exhaust_vacuum"],df_cleaned["energy_production"],color = "blue")
plt.show()
plt.figure(figsize=(30,7))


# In[43]:


import matplotlib.pyplot as plt

plt.figure(figsize=(30,10))
plt.scatter(df_cleaned["amb_pressure"],df_cleaned["energy_production"],color = "green")
plt.show()
plt.figure(figsize=(30,7))


# In[44]:


import matplotlib.pyplot as plt

plt.figure(figsize=(30,10))
plt.scatter(df_cleaned["r_humidity"],df_cleaned["energy_production"],color = "orange")
plt.show()
plt.figure(figsize=(30,7))


# In[45]:


df_cleaned['temperature'].hist()


# In[46]:


df_cleaned['exhaust_vacuum'].hist()


# In[47]:


df_cleaned['amb_pressure'].hist()


# In[48]:


df_cleaned['r_humidity'].hist()


# In[49]:


features=[feature for feature in df_cleaned.columns if df_cleaned[feature].dtypes != 'O']
for feat in features:
    skew = df_cleaned[feat].skew()
    sns.distplot(df_cleaned[feat], kde= False, label='Skew = %.3f' %(skew), bins=30,color = 'red')
    plt.legend(loc='best')
    plt.show()


# In[50]:


import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'df_cleaned' is your DataFrame
sns.set(style="ticks")  # Set the plot style

# Define the figure size
plt.figure(figsize=(10, 8))

# Create the pairplot with specific figure size
pairplot = sns.pairplot(df_cleaned)

# Customize plot aesthetics further if needed

# Show the pairplot
plt.show()


# In[51]:


#observe the distribution of numeric data


import seaborn as sns
import matplotlib.pyplot as plt
sns.violinplot(x=df_cleaned['temperature'])

# Show the plot
plt.show()


# In[52]:


import seaborn as sns
import matplotlib.pyplot as plt
sns.violinplot(x=df_cleaned['exhaust_vacuum'])

# Show the plot
plt.show()


# In[53]:


import seaborn as sns
import matplotlib.pyplot as plt
sns.violinplot(x=df_cleaned['amb_pressure'])

# Show the plot
plt.show()


# In[54]:


import seaborn as sns
import matplotlib.pyplot as plt
sns.violinplot(x=df_cleaned['r_humidity'])

# Show the plot
plt.show()


# In[55]:


df_cleaned.head()


# In[56]:


sns.distplot(df_cleaned['temperature'])
plt.show()     # almost normal distrubution


# In[57]:


sns.distplot(df_cleaned['exhaust_vacuum'])
plt.show()


# In[58]:


df_cleaned['exhaust_vacuum'] = np.log(df_cleaned['exhaust_vacuum'])


# In[59]:


sns.distplot(df_cleaned['exhaust_vacuum'])
plt.show()


# In[ ]:

# In[60]:


sns.distplot(df_cleaned['amb_pressure'])
plt.show()     # almost normal distrubution


# In[61]:


sns.distplot(df_cleaned['r_humidity'])
plt.show()      #  slightly positive skewed


# In[62]:


df_cleaned.corr()


# In[63]:


plt.figure(figsize=(15,7))
sns.heatmap(df_cleaned.corr(),annot=True,cmap='plasma')


# In[64]:


# i have positive correlation on independent features

import matplotlib.pyplot as plt

plt.figure(figsize=(30,10))
plt.scatter(df_cleaned["temperature"],df_cleaned["exhaust_vacuum"],color = "red")
plt.show()
plt.figure(figsize=(30,7))


# In[65]:


# i have some -ve  correlation on independent features

import matplotlib.pyplot as plt

plt.figure(figsize=(30,10))
plt.scatter(df_cleaned["temperature"],df_cleaned["r_humidity"],color = "black")
plt.show()
plt.figure(figsize=(30,7))


# In[66]:


from sklearn.preprocessing import MinMaxScaler

# minmax = X - X(min)  /  X(max) - X(min)


# In[67]:


df_cleaned.head()


# In[68]:


# MinMax convert data into 0 to 1

MM = MinMaxScaler()

df_cleaned['temperature'] = MM.fit_transform(df_cleaned[['temperature']])

df_cleaned['exhaust_vacuum'] = MM.fit_transform(df_cleaned[['exhaust_vacuum']])

df_cleaned['amb_pressure'] = MM.fit_transform(df_cleaned[['amb_pressure']])

df_cleaned['r_humidity'] = MM.fit_transform(df_cleaned[['r_humidity']])


# In[69]:


df_cleaned.head()


# # Split Data into Train and Test

# In[70]:


X = df_cleaned.iloc[:,:4]
X.head()


# In[71]:


Y = df_cleaned['energy_production']
Y.head()


# In[72]:


from sklearn.model_selection import train_test_split


# In[73]:


X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = .25,random_state = 42)


# In[74]:


X_train.shape


# In[75]:


X_test.shape


# In[76]:


X_train.info()
X_train.describe()


# In[77]:


X_train.head()


# In[78]:


X_train.tail()


# In[79]:


X_test.head()


# In[80]:


X_test.tail()


# In[81]:


Y_train.shape


# In[82]:


Y_test.shape


# In[83]:


Y_train.info()
Y_train.describe()


# In[84]:


print(Y_test.head())
Y_test.tail()


# In[85]:


#this is the train data distribution

import matplotlib.pyplot as plt

plt.scatter(X_train['temperature'], Y_train, color='black')
plt.xlabel('temperature')
plt.ylabel('energy_production')
plt.show()


# In[86]:


print(Y_train.head())
Y_train.tail()


# In[87]:


# Import necessary libraries
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.ensemble import AdaBoostRegressor
from sklearn.metrics import mean_squared_error, r2_score


# In[88]:


# Create and train a Linear Regression model
linear_model = LinearRegression()
linear_model.fit(X_train, Y_train)


# In[97]:


# Make predictions using the Linear Regression model
linear_predictions = linear_model.predict(X_test)

# Evaluate the Linear Regression model
linear_mse = mean_squared_error(Y_test, linear_predictions)
linear_r2 = r2_score(Y_test, linear_predictions)
print("Linear Regression MSE:", linear_mse)
print("Linear Regression R-squared:", linear_r2)


# In[98]:


# Create and train a Lasso Regression model
lasso_model = Lasso(alpha=1.0)  # You can adjust the alpha parameter
lasso_model.fit(X_train, Y_train)


# In[99]:


# Make predictions using the Lasso Regression model
lasso_predictions = lasso_model.predict(X_test)

# Evaluate the Lasso Regression model
lasso_mse = mean_squared_error(Y_test, lasso_predictions)
lasso_r2 = r2_score(Y_test, lasso_predictions)
print("Lasso Regression MSE:", lasso_mse)
print("Lasso Regression R-squared:", lasso_r2)


# In[100]:


# Create and train a Ridge Regression model
ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha parameter
ridge_model.fit(X_train, Y_train)


# In[101]:


# Make predictions using the Ridge Regression model
ridge_predictions = ridge_model.predict(X_test)

# Evaluate the Ridge Regression model
ridge_mse = mean_squared_error(Y_test, ridge_predictions)
ridge_r2 = r2_score(Y_test, ridge_predictions)
print("Ridge Regression MSE:", ridge_mse)
print("Ridge Regression R-squared:", ridge_r2)


# In[102]:


# Create and train an AdaBoost Regressor
adaboost_model = AdaBoostRegressor(n_estimators=50, learning_rate=0.1, random_state=42)  # You can adjust the hyperparameters
adaboost_model.fit(X_train, Y_train)


# In[103]:


# Make predictions using the AdaBoost Regressor
adaboost_predictions = adaboost_model.predict(X_test)

# Evaluate the AdaBoost Regressor
adaboost_mse = mean_squared_error(Y_test, adaboost_predictions)
adaboost_r2 = r2_score(Y_test, adaboost_predictions)
print("AdaBoost Regression MSE:", adaboost_mse)
print("AdaBoost Regression R-squared:", adaboost_r2)


# In[ ]:





# In[106]:


# Decsion tree
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import Lasso
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Decision Tree Regression
decision_tree = DecisionTreeRegressor(random_state=42)
decision_tree.fit(X_train, Y_train)



# In[107]:


# Lasso Regression
lasso_regression = Lasso(alpha=0.01, random_state=42)
lasso_regression.fit(X_train, Y_train)


# In[108]:


# Gradient Boosting Regression
gradient_boosting = GradientBoostingRegressor(n_estimators=100, random_state=42)
gradient_boosting.fit(X_train, Y_train)


# In[109]:


# Predictions
dt_predictions = decision_tree.predict(X_test)
lasso_predictions = lasso_regression.predict(X_test)
gb_predictions = gradient_boosting.predict(X_test)

# Evaluation
def evaluate_model(name, predictions):
    mse = mean_squared_error(Y_test, predictions)
    r2 = r2_score(Y_test, predictions)
    print(f"{name} Model:")
    print(f"Mean Squared Error: {mse:.2f}")
    print(f"R-squared: {r2:.2f}")
    print("\n")

evaluate_model("Decision Tree", dt_predictions)
evaluate_model("Lasso Regression", lasso_predictions)
evaluate_model("Gradient Boosting", gb_predictions)


# In[ ]:





# In[ ]:


#random forest


# In[111]:


from sklearn.ensemble import RandomForestRegressor

# Create a Random Forest Regressor
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model on the training data
rf_regressor.fit(X_train, Y_train)

# Predict on the test data
rf_predictions = rf_regressor.predict(X_test)

# Evaluate the model
from sklearn.metrics import mean_squared_error, r2_score

rf_mse = mean_squared_error(Y_test, rf_predictions)
rf_r2 = r2_score(Y_test, rf_predictions)

print("Random Forest Regression MSE:", rf_mse)
print("Random Forest Regression R^2:", rf_r2)


# In[112]:


from sklearn.linear_model import Lasso

# Create a Lasso Regressor
lasso_regressor = Lasso(alpha=0.001, random_state=42)

# Fit the model on the training data
lasso_regressor.fit(X_train, Y_train)

# Predict on the test data
lasso_predictions = lasso_regressor.predict(X_test)

# Evaluate the model
lasso_mse = mean_squared_error(Y_test, lasso_predictions)
lasso_r2 = r2_score(Y_test, lasso_predictions)

print("Lasso Regression MSE:", lasso_mse)
print("Lasso Regression R^2:", lasso_r2)


# In[113]:


from sklearn.linear_model import Ridge

# Create a Ridge Regressor
ridge_regressor = Ridge(alpha=1.0, random_state=42)

# Fit the model on the training data
ridge_regressor.fit(X_train, Y_train)

# Predict on the test data
ridge_predictions = ridge_regressor.predict(X_test)

# Evaluate the model
ridge_mse = mean_squared_error(Y_test, ridge_predictions)
ridge_r2 = r2_score(Y_test, ridge_predictions)

print("Ridge Regression MSE:", ridge_mse)
print("Ridge Regression R^2:", ridge_r2)

pip install xgboost

import xgboost as xgb

# Create an XGBoost Regressor
xgb_regressor = xgb.XGBRegressor(objective="reg:squarederror", random_state=42)

# Fit the model on the training data
xgb_regressor.fit(X_train, Y_train)

# Predict on the test data
xgb_predictions = xgb_regressor.predict(X_test)

# Evaluate the model
xgb_mse = mean_squared_error(Y_test, xgb_predictions)
xgb_r2 = r2_score(Y_test, xgb_predictions)

print("XGBoost Regression MSE:", xgb_mse)
print("XGBoost Regression R^2:", xgb_r2)


# In[ ]:


#  Support Vector Regression


# In[119]:


# Import necessary libraries
from sklearn.svm import SVR
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# In[122]:


# SVM model with Ridge regression (SVR)
svm_ridge_model = SVR(kernel='linear')
svm_ridge_model.fit(X_train_scaled, Y_train)




# In[123]:


# Predict using SVM model
svm_ridge_predictions = svm_ridge_model.predict(X_test_scaled)


# Calculate RMSE (Root Mean Squared Error) for SVM with Ridge
svm_ridge_rmse = mean_squared_error(Y_test, svm_ridge_predictions, squared=False)
print(f"RMSE for SVM with Ridge: {svm_ridge_rmse}")


# In[124]:


# Gradient Boosting Regression
gboost_model = GradientBoostingRegressor()
gboost_model.fit(X_train_scaled, Y_train)

# Predict using Gradient Boosting Regression
gboost_predictions = gboost_model.predict(X_test_scaled)

# Calculate RMSE for Gradient Boosting Regression
gboost_rmse = mean_squared_error(Y_test, gboost_predictions, squared=False)
print(f"RMSE for Gradient Boosting Regression: {gboost_rmse}")


# In[ ]:

